{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aaf1bd5",
   "metadata": {},
   "source": [
    "## <center> Image recognition </center>\n",
    "### <center> Train your own model vs Transfer learning </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "688cb234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.utils import to_categorical, load_img\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.applications import vgg16, resnet\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59167aa2",
   "metadata": {},
   "source": [
    "### I. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f3b8ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95e02993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "X_test shape: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('X_test shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e8f04d",
   "metadata": {},
   "source": [
    "- CIFAR10 is 60K image split into 50K on train and 10 on test. Each image size is: 32 x 32 x 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cec848",
   "metadata": {},
   "source": [
    "### II. Preprocessing images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10346e3a",
   "metadata": {},
   "source": [
    "#### 1. Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaf8745",
   "metadata": {},
   "source": [
    "First, let's convert our data into float variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fd721be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3f2e7b",
   "metadata": {},
   "source": [
    "Next, let's divide by 255 to normalize data between 0 & 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ebad3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9402ad0",
   "metadata": {},
   "source": [
    "#### 2. Convert labels to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47eb57b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_test = to_categorical(y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d7ef26",
   "metadata": {},
   "source": [
    "### III. Trained from scratch model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12f5499",
   "metadata": {},
   "source": [
    "#### 1. Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbd598ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First convolution block\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(32, 32, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Second convolution block\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Third convolution block\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten then dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "# Output layer\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Model compilation\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Tensorboard logging\n",
    "logger = TensorBoard(log_dir='logs/3Conv_blocks', write_graph=True, histogram_freq=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "384c03dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 16, 16, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 8, 8, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 8, 8, 32)          0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 8, 8, 32)          9248      \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 8, 8, 32)          9248      \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 4, 4, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 4, 4, 32)          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 181,034\n",
      "Trainable params: 181,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3792deda",
   "metadata": {},
   "source": [
    "#### 2. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ee8a409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 41s 24ms/step - loss: 1.6862 - accuracy: 0.3730 - val_loss: 1.3368 - val_accuracy: 0.5086\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 1.3113 - accuracy: 0.5258 - val_loss: 1.1875 - val_accuracy: 0.5671\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 1.1673 - accuracy: 0.5820 - val_loss: 1.0401 - val_accuracy: 0.6371\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.0709 - accuracy: 0.6189 - val_loss: 0.9487 - val_accuracy: 0.6663\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.0093 - accuracy: 0.6409 - val_loss: 0.8926 - val_accuracy: 0.6870\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 0.9640 - accuracy: 0.6590 - val_loss: 0.8352 - val_accuracy: 0.7073\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.9208 - accuracy: 0.6737 - val_loss: 0.8316 - val_accuracy: 0.7061\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.8986 - accuracy: 0.6803 - val_loss: 0.7951 - val_accuracy: 0.7239\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 49s 32ms/step - loss: 0.8695 - accuracy: 0.6916 - val_loss: 0.7771 - val_accuracy: 0.7286\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 0.8510 - accuracy: 0.7001 - val_loss: 0.7665 - val_accuracy: 0.7363\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.8317 - accuracy: 0.7067 - val_loss: 0.7948 - val_accuracy: 0.7232\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.8225 - accuracy: 0.7098 - val_loss: 0.7652 - val_accuracy: 0.7387\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 0.8048 - accuracy: 0.7175 - val_loss: 0.7438 - val_accuracy: 0.7405\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.7945 - accuracy: 0.7185 - val_loss: 0.7340 - val_accuracy: 0.7427\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.7790 - accuracy: 0.7258 - val_loss: 0.7314 - val_accuracy: 0.7460\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 51s 32ms/step - loss: 0.7820 - accuracy: 0.7267 - val_loss: 0.7220 - val_accuracy: 0.7489\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.7615 - accuracy: 0.7331 - val_loss: 0.7043 - val_accuracy: 0.7531\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.7555 - accuracy: 0.7345 - val_loss: 0.7524 - val_accuracy: 0.7397\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.7447 - accuracy: 0.7371 - val_loss: 0.7050 - val_accuracy: 0.7568\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.7398 - accuracy: 0.7414 - val_loss: 0.7002 - val_accuracy: 0.7585\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 51s 32ms/step - loss: 0.7397 - accuracy: 0.7391 - val_loss: 0.7346 - val_accuracy: 0.7386\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 0.7302 - accuracy: 0.7418 - val_loss: 0.6936 - val_accuracy: 0.7616\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.7240 - accuracy: 0.7462 - val_loss: 0.6887 - val_accuracy: 0.7630\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.7191 - accuracy: 0.7485 - val_loss: 0.6825 - val_accuracy: 0.7661\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.7101 - accuracy: 0.7513 - val_loss: 0.6975 - val_accuracy: 0.7628\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.7053 - accuracy: 0.7516 - val_loss: 0.7040 - val_accuracy: 0.7595\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.7097 - accuracy: 0.7521 - val_loss: 0.6646 - val_accuracy: 0.7726\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.6987 - accuracy: 0.7562 - val_loss: 0.6798 - val_accuracy: 0.7647\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.7006 - accuracy: 0.7525 - val_loss: 0.6869 - val_accuracy: 0.7631\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6967 - accuracy: 0.7566 - val_loss: 0.6620 - val_accuracy: 0.7720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc19e6abc0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    epochs=30,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a49ea1",
   "metadata": {},
   "source": [
    "#### 3. Saving the model's structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "180101dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5872"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_structure = model.to_json()\n",
    "f = Path('model_structure.json')\n",
    "f.write_text(model_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b544fe",
   "metadata": {},
   "source": [
    "#### 4. Saving the model's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d858eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa049eb2",
   "metadata": {},
   "source": [
    "#### 5. Loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a1d5a4",
   "metadata": {},
   "source": [
    "- Loading the model's structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57fafe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('model_structure.json')\n",
    "model_structure = p.read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4bd2dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_from_json(model_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ed99dc",
   "metadata": {},
   "source": [
    "- Loading the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e108a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_weights.h5')\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfffd37",
   "metadata": {},
   "source": [
    "#### 6. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5246d3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6620 - accuracy: 0.7720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.662005603313446, 0.7720000147819519]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cb9745",
   "metadata": {},
   "source": [
    "#### 7. Model prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3c5967",
   "metadata": {},
   "source": [
    "- Loading external images to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76f3ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "frog = load_img(\"test_images/frog.png\", target_size=(32, 32))\n",
    "bay = load_img(\"test_images/bay.jpg\", target_size=(32, 32))\n",
    "dog = load_img(\"test_images/dog.png\", target_size=(32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ff3b47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\n",
    "    \"Plane\",\n",
    "    \"Car\",\n",
    "    \"Bird\",\n",
    "    \"Cat\",\n",
    "    \"Deer\",\n",
    "    \"Dog\",\n",
    "    \"Frog\",\n",
    "    \"Horse\",\n",
    "    \"Boat\",\n",
    "    \"Truck\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410df82b",
   "metadata": {},
   "source": [
    "- Predicting the 3 test image's class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f4a2291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 234ms/step\n",
      "['Frog', 'Car', 'Car']\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(np.stack([frog, bay, dog], axis=0))\n",
    "pred_classes = []\n",
    "for prob in pred:\n",
    "    most_likely = int(np.argmax(prob))\n",
    "    class_label = class_labels[most_likely]\n",
    "    pred_classes.append(class_label)\n",
    "print(pred_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce604b2",
   "metadata": {},
   "source": [
    "### IV. Transfer Learning - VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e97dab0",
   "metadata": {},
   "source": [
    "#### 0. Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da538f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_test = to_categorical(y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbb3a8d",
   "metadata": {},
   "source": [
    "#### 1. Pretrained VGG16 without output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ffb376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = vgg16.VGG16(weights=\"imagenet\",\n",
    "                               include_top=False,\n",
    "                               input_shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9f0d83",
   "metadata": {},
   "source": [
    "#### 2. Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92778676",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vgg16.preprocess_input(X_train)\n",
    "X_test = vgg16.preprocess_input(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd9c4d",
   "metadata": {},
   "source": [
    "#### 3. Extracting images fautures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe182819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 220s 139ms/step\n",
      "313/313 [==============================] - 48s 145ms/step\n"
     ]
    }
   ],
   "source": [
    "features_train = pretrained_model.predict(X_train)\n",
    "features_test = pretrained_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aba8f0",
   "metadata": {},
   "source": [
    "#### 3. Fine-tuning the model to our use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "03dba748",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=features_train.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c735bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Tensorboard logging\n",
    "logger = TensorBoard(log_dir='logs/fined-tuned-vgg16', write_graph=True, histogram_freq=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5e0c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(features_train,\n",
    "          y_train,\n",
    "          validation_data = (features_test, y_test),\n",
    "          epochs=50,\n",
    "          callbacks = [logger],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f76b368",
   "metadata": {},
   "source": [
    "### IV. Transfer Learning - Resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d2704",
   "metadata": {},
   "source": [
    "#### 0. Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "38444557",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_test = to_categorical(y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35805519",
   "metadata": {},
   "source": [
    "#### 1. Pretrained ResNet50 without output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f716d5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 22s 0us/step\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = resnet.ResNet50(weights=\"imagenet\",\n",
    "                               include_top=False,\n",
    "                               input_shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adf26e8",
   "metadata": {},
   "source": [
    "#### 2. Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d4c07e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = resnet.preprocess_input(X_train)\n",
    "X_test = resnet.preprocess_input(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c3ce22",
   "metadata": {},
   "source": [
    "#### 3. Extracting images fautures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4f3d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  74/1563 [>.............................] - ETA: 1:59"
     ]
    }
   ],
   "source": [
    "features_train = pretrained_model.predict(X_train)\n",
    "features_test = pretrained_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e03e96",
   "metadata": {},
   "source": [
    "#### 3. Fine-tuning the model to our use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d60e723",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=features_train.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "892d1765",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Tensorboard logging\n",
    "logger = TensorBoard(log_dir='logs/fined-tuned-vgg16', write_graph=True, histogram_freq=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1e07756d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 10s 4ms/step - loss: 0.3575 - accuracy: 0.4810 - val_loss: 0.1833 - val_accuracy: 0.6140\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2009 - accuracy: 0.5785 - val_loss: 0.1728 - val_accuracy: 0.6354\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1888 - accuracy: 0.6088 - val_loss: 0.1683 - val_accuracy: 0.6522\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1827 - accuracy: 0.6234 - val_loss: 0.1660 - val_accuracy: 0.6574\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1777 - accuracy: 0.6341 - val_loss: 0.1631 - val_accuracy: 0.6610\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1739 - accuracy: 0.6446 - val_loss: 0.1644 - val_accuracy: 0.6668\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1709 - accuracy: 0.6472 - val_loss: 0.1647 - val_accuracy: 0.6621\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1686 - accuracy: 0.6561 - val_loss: 0.1645 - val_accuracy: 0.6625\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1646 - accuracy: 0.6630 - val_loss: 0.1646 - val_accuracy: 0.6678\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1629 - accuracy: 0.6691 - val_loss: 0.1657 - val_accuracy: 0.6705\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1601 - accuracy: 0.6730 - val_loss: 0.1647 - val_accuracy: 0.6702\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1580 - accuracy: 0.6777 - val_loss: 0.1654 - val_accuracy: 0.6707\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1558 - accuracy: 0.6831 - val_loss: 0.1672 - val_accuracy: 0.6681\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1543 - accuracy: 0.6838 - val_loss: 0.1674 - val_accuracy: 0.6693\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1526 - accuracy: 0.6903 - val_loss: 0.1694 - val_accuracy: 0.6701\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 5s 4ms/step - loss: 0.1504 - accuracy: 0.6900 - val_loss: 0.1714 - val_accuracy: 0.6683\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1496 - accuracy: 0.6929 - val_loss: 0.1705 - val_accuracy: 0.6739\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1476 - accuracy: 0.6990 - val_loss: 0.1758 - val_accuracy: 0.6698\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1465 - accuracy: 0.7000 - val_loss: 0.1720 - val_accuracy: 0.6733\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1444 - accuracy: 0.7034 - val_loss: 0.1733 - val_accuracy: 0.6698\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1431 - accuracy: 0.7067 - val_loss: 0.1786 - val_accuracy: 0.6624\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1418 - accuracy: 0.7086 - val_loss: 0.1759 - val_accuracy: 0.6759\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1409 - accuracy: 0.7123 - val_loss: 0.1807 - val_accuracy: 0.6670\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1404 - accuracy: 0.7125 - val_loss: 0.1817 - val_accuracy: 0.6679\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1396 - accuracy: 0.7128 - val_loss: 0.1820 - val_accuracy: 0.6680\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1390 - accuracy: 0.7148 - val_loss: 0.1811 - val_accuracy: 0.6723\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1365 - accuracy: 0.7197 - val_loss: 0.1859 - val_accuracy: 0.6720\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1366 - accuracy: 0.7183 - val_loss: 0.1846 - val_accuracy: 0.6683\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1358 - accuracy: 0.7212 - val_loss: 0.1883 - val_accuracy: 0.6703\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1347 - accuracy: 0.7225 - val_loss: 0.1885 - val_accuracy: 0.6708\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1335 - accuracy: 0.7236 - val_loss: 0.1919 - val_accuracy: 0.6674\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1320 - accuracy: 0.7289 - val_loss: 0.1983 - val_accuracy: 0.6669\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1328 - accuracy: 0.7253 - val_loss: 0.1942 - val_accuracy: 0.6749\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1325 - accuracy: 0.7258 - val_loss: 0.1973 - val_accuracy: 0.6681\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1318 - accuracy: 0.7292 - val_loss: 0.1972 - val_accuracy: 0.6713\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1300 - accuracy: 0.7319 - val_loss: 0.1993 - val_accuracy: 0.6719\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1306 - accuracy: 0.7302 - val_loss: 0.2026 - val_accuracy: 0.6724\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1281 - accuracy: 0.7319 - val_loss: 0.2043 - val_accuracy: 0.6633\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1276 - accuracy: 0.7354 - val_loss: 0.2064 - val_accuracy: 0.6691\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1273 - accuracy: 0.7340 - val_loss: 0.2070 - val_accuracy: 0.6692\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1267 - accuracy: 0.7351 - val_loss: 0.2074 - val_accuracy: 0.6678\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1268 - accuracy: 0.7353 - val_loss: 0.2154 - val_accuracy: 0.6631\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1267 - accuracy: 0.7355 - val_loss: 0.2147 - val_accuracy: 0.6694\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1261 - accuracy: 0.7375 - val_loss: 0.2133 - val_accuracy: 0.6653\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1254 - accuracy: 0.7405 - val_loss: 0.2164 - val_accuracy: 0.6624\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1247 - accuracy: 0.7382 - val_loss: 0.2212 - val_accuracy: 0.6642\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1242 - accuracy: 0.7437 - val_loss: 0.2208 - val_accuracy: 0.6639\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1239 - accuracy: 0.7415 - val_loss: 0.2195 - val_accuracy: 0.6644\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1231 - accuracy: 0.7414 - val_loss: 0.2223 - val_accuracy: 0.6687\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1226 - accuracy: 0.7427 - val_loss: 0.2291 - val_accuracy: 0.6643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b613a073a0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features_train,\n",
    "          y_train,\n",
    "          validation_data = (features_test, y_test),\n",
    "          epochs=50,\n",
    "          callbacks = [logger],\n",
    "          shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
